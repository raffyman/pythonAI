{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LOGIC BUILDING PROGRAMS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enter a number\n",
      "7\n",
      "Factorial of the number is: 5040 \n"
     ]
    }
   ],
   "source": [
    "#FIND FACTORIAL\n",
    "def factorial(l):\n",
    "    if(l==0 or l==1):\n",
    "        return 1\n",
    "    else:\n",
    "        return l*factorial(l-1)\n",
    "\n",
    "print(\"enter a number\")\n",
    "n=int(input())\n",
    "\n",
    "print(\"Factorial of the number is: %d \"%factorial(n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter a number\n",
      "91\n",
      "PRIME NUM\n"
     ]
    }
   ],
   "source": [
    "#program to chekc if prime or composite number\n",
    "print('Enter a number')\n",
    "n=int(input())\n",
    "\n",
    "for i in range(2,n+1):\n",
    "    if(n%i==0):\n",
    "        print(\"composite number\")\n",
    "        break\n",
    "\n",
    "    if(n%n==0):\n",
    "        print(\"PRIME NUM\")\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list 1:  50000\n",
      "list 2 [4, 5, 6, 7, 8, 9]\n",
      "list 3: ['Bahawalpur', 1993]\n"
     ]
    }
   ],
   "source": [
    "#working with lists\n",
    "lst1 = ['usman','m.phil',50000,8000]\n",
    "lst2 = [1,2,3,4,5,6,7,8,9]\n",
    "lst3 = ['Muhammad Usman Sarwar','Bahawalpur',1993,True]\n",
    "\n",
    "print(\"list 1: \",lst1[2])\n",
    "print(\"list 2\",lst2[3:9])\n",
    "print(\"list 3:\",lst3[1:3])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 'WOW', 5, 6, 7, 8]\n",
      "[1, 2, 3, 'WOW', 'GRAPE', 6, 7, 8]\n"
     ]
    }
   ],
   "source": [
    "#update list\n",
    "lst = [1,2,3,4,5,6,7,8]\n",
    "lst[3]=\"WOW\"\n",
    "print(lst)\n",
    "lst[4]=\"GRAPE\"\n",
    "print(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100.0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Write a Python program to convert these numbers into string then into float #types:10,20,30,40,50,60,70,80,90,100\n",
    "#nums = (10,20,30,40,50,60,70,80,90,100)\n",
    "num_1 = 10\n",
    "str(num_1)\n",
    "float(num_1)\n",
    "num_2= 20\n",
    "str(num_2)\n",
    "float(num_2)\n",
    "num_3 = 30\n",
    "str(num_3)\n",
    "float(num_3)\n",
    "num_4 = 40\n",
    "str(num_4)\n",
    "float(num_4)\n",
    "num_5 = 50\n",
    "str(num_5)\n",
    "float(num_5)\n",
    "num_6 = 60\n",
    "str(num_6)\n",
    "float(num_6)\n",
    "num_7 =70\n",
    "str(num_7)\n",
    "float(num_7)\n",
    "num_8 = 80\n",
    "str(num_8)\n",
    "float(num_8)\n",
    "num_9= 90\n",
    "str(num_9)\n",
    "float(num_9)\n",
    "num_10 = 100\n",
    "str(num_10)\n",
    "float(num_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter name\n",
      "john\n",
      "Enter car color\n",
      "blue\n",
      "Hello my name is john and the color of my car is blue\n",
      "hello my name is john and the color of my car is blue\n"
     ]
    }
   ],
   "source": [
    "#String Functions\n",
    "print(\"Enter name\")\n",
    "name = str(input())\n",
    "print(\"Enter car color\")\n",
    "car_color  = str(input())\n",
    "print(\"Hello my name is \"+name+\" and the color of my car is \"+car_color)\n",
    "msg=\"hello my name is {} and the color of my car is {}\".format(name,car_color)\n",
    "print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python is user friendly  & easy  language and suitable for data analysis\n"
     ]
    }
   ],
   "source": [
    "#Write a program in python that take two string to complete and form a message that we can understand?\n",
    "str1=\"user friendly\"\n",
    "str2=\"easy\"\n",
    "msg = \"python is {}  & {}  language and suitable for data analysis\".format(str1,str2)\n",
    "print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['alone', 'study', 'prayers', 'Memories']\n",
      "After deleting the new list is  ['alone', 'study', 'prayers']\n"
     ]
    }
   ],
   "source": [
    "#deleting element from the list\n",
    "habit = ['alone','study','prayers','Memories']\n",
    "print(habit)\n",
    "del habit[3]\n",
    "print(\"After deleting the new list is \",habit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the name of your favourite programming:\n",
      "RubyOnRails\n",
      "The length of your favourite programing language is  11\n"
     ]
    }
   ],
   "source": [
    "#write  a program in python to declare the name of this programming language and calculate length of this name.\n",
    "print(\"Enter the name of your favourite programming:\")\n",
    "str1=str(input())\n",
    "lengthOfStr=len(str1)\n",
    "print(\"The length of your favourite programing language is \",lengthOfStr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['job', 'm.fill', 'phd', 'business']\n",
      "['job', 'm.fill', 'phd']\n"
     ]
    }
   ],
   "source": [
    "#remove using the word in the list\n",
    "goal = ['job','m.fill','phd','business']\n",
    "print(goal)\n",
    "r =goal.remove('business')\n",
    "print(goal)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "#write a program in python to declare a message for an instructing sign in public place and get the length of that message and count of message letters:\n",
    "msg=\"ImPORTANT message: Kindly avoid using horn near hospital or school area. If you get to know about the message then spread the message\"\n",
    "lengthOfmsg=len(msg)\n",
    "countLength = msg.count('message')\n",
    "print(lengthOfmsg)\n",
    "print(countLength)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    }
   ],
   "source": [
    "#Write a program in python to count to count the vowels in the following string:\n",
    "vowel=\" are you working as a Python programmer ?\"\n",
    "Total_Vowels= vowel.count('a') + vowel.count('e') + vowel.count('i') + vowel.count('o') + vowel.count('u')\n",
    "print(Total_Vowels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THE FOUR MESSAGES ARE: \n",
      "\n",
      "the Python programming language is wonderful\n",
      "The Python language is elegant\n",
      "The Python language is poweful\n",
      "The Python language is suitable for data analysis\n",
      "length of each message is: \n",
      "44\n",
      "30\n",
      "30\n",
      "49\n",
      "the count of letter 'a' in first message is\n",
      "3\n",
      "the count of letter 'e' in second message is\n",
      "4\n",
      "the count of letter 'o' in third message is\n",
      "2\n",
      "the count of letter 'u' in fourth message is\n",
      "2\n",
      "Do the messages start with 'l'\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "Do the messages end with 'T'\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "#Write  a program in python to declare four messages\n",
    "# to the community of technology that\n",
    "# but describe python with  a different description in each message you will write ,\n",
    "# so with one message withe one python description then answer the following questions:\n",
    "msg1=\"the Python programming language is wonderful\"\n",
    "msg2=\"The Python language is elegant\"\n",
    "msg3=\"The Python language is poweful\"\n",
    "msg4=\"The Python language is suitable for data analysis\"\n",
    "print(\"THE FOUR MESSAGES ARE: \\n\")\n",
    "print(msg1)\n",
    "print(msg2)\n",
    "print(msg3)\n",
    "print(msg4)\n",
    "\n",
    "#How long each message you write is?\n",
    "print('length of each message is: ')\n",
    "l1= len(msg1)\n",
    "l2= len(msg2)\n",
    "l3= len(msg3)\n",
    "l4= len(msg4)\n",
    "print(l1)\n",
    "print(l2)\n",
    "print(l3)\n",
    "print(l4)\n",
    "\n",
    "#what is the count of a specific letter in each message you will write?\n",
    "print(\"the count of letter 'a' in first message is\")\n",
    "print(msg1.count('a'))\n",
    "print(\"the count of letter 'e' in second message is\")\n",
    "print(msg2.count('e'))\n",
    "print(\"the count of letter 'o' in third message is\")\n",
    "print(msg3.count('o'))\n",
    "print(\"the count of letter 'u' in fourth message is\")\n",
    "print(msg4.count('u'))\n",
    "\n",
    "#are the codes you write end with \"l\"?\n",
    "print(\"Do the messages start with 'l'\")\n",
    "print(msg1.startswith('l'))\n",
    "print(msg2.startswith('l'))\n",
    "print(msg3.startswith('l'))\n",
    "print(msg4.startswith('l'))\n",
    "\n",
    "#are the codes you write start with \"T\"?\n",
    "print(\"Do the messages end with 'T'\")\n",
    "print(msg1.endswith('T'))\n",
    "print(msg2.endswith('T'))\n",
    "print(msg3.endswith('T'))\n",
    "print(msg4.endswith('T'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n",
      "-1\n"
     ]
    }
   ],
   "source": [
    "#Write a program in python\n",
    "# contain string \"Don't turn left!\" and\n",
    "# then check if this string contain ( '!') and('m')\n",
    "\n",
    "String = \"Don't turn left!\"\n",
    "print(String.find('!'))\n",
    "print(String.find('m'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'EmpId': 100, 'Emp_Name': 'RobinHood', 'Emp_Salary': 5000}, {'EmpId': 200, 'Emp_Name': 'Racheal Hood', 'Emp_Salary': 6500}, {'EmpId': 300, 'Emp_Name': 'Ben Ten', 'Emp_Salary': 5900}]\n"
     ]
    }
   ],
   "source": [
    "#Dictionary\n",
    "record = [\n",
    "    {\"EmpId\":100,\"Emp_Name\":\"RobinHood\",\"Emp_Salary\":5000},\n",
    "    {\"EmpId\":200,\"Emp_Name\":\"Racheal Hood\",\"Emp_Salary\":6500},\n",
    "    {\"EmpId\":300,\"Emp_Name\":\"Ben Ten\",\"Emp_Salary\":5900}\n",
    "]\n",
    "print(record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n",
      "DON'T TURN LEFT\n",
      "don't turn left\n"
     ]
    }
   ],
   "source": [
    "# write a program in python contain  a string\n",
    "# for an electrical instructional sign in the street\n",
    "# warning the cars drivers that they don't to turn left.\n",
    "# then check the string case.\n",
    "# then make it in upper case  in one code\n",
    "# finally make it in lower case in a second code.\n",
    "\n",
    "msg = \"Don't turn left\"\n",
    "print(msg.isupper())\n",
    "print(msg.islower())\n",
    "print(msg.upper())\n",
    "print(msg.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The coding is fun\n",
      "The coding is awesome\n",
      " coding is awesom\n"
     ]
    }
   ],
   "source": [
    "#write a program in python to declare that\n",
    "# The coding is fun, then replace the word 'fun' with  the 'awesome'\n",
    "# and then remove the word ' The'\n",
    "\n",
    "st=\"The coding is fun\"\n",
    "print(st)\n",
    "st=st.replace('fun','awesome')\n",
    "print(st)\n",
    "st=st.strip('The')\n",
    "print(st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python is powerful language\n",
      "1st programming language\n",
      "Python is powerful programming language\n",
      "Python The Powerful Programming Language\n"
     ]
    }
   ],
   "source": [
    "string = 'python is powerful language'\n",
    "print(string.capitalize())\n",
    "string = '1st programming language'\n",
    "print(string.capitalize())\n",
    "string = 'pYTHON IS POWERFUL PROGRAMMING LANGUAGE'\n",
    "print(string.swapcase())\n",
    "string = 'Python the powerful programming language'\n",
    "print(string.title())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 2.2, 3.1, 4, 5, 6, 'one', 'two', 'tree')\n"
     ]
    }
   ],
   "source": [
    "#tuples\n",
    "hacking = (1,2.2,3.1,4,5,6,\"one\",\"two\",\"tree\")\n",
    "print(hacking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 2.2, 3.1, 4, 5, 6, 'one', 'two', 'tree')\n",
      "('usman', 'm.fill', 'self request')\n",
      "(1, 2.2, 3.1, 4, 5, 6, 'one', 'two', 'tree', 'usman', 'm.fill', 'self request')\n"
     ]
    }
   ],
   "source": [
    "#Updating tuples\n",
    "hacking = (1,2.2,3.1,4,5,6,\"one\",\"two\",\"tree\")\n",
    "print(hacking)\n",
    "success = ('usman','m.fill','self request')\n",
    "print(success)\n",
    "\n",
    "hackngSuccess=hacking+success\n",
    "print(hackngSuccess)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12181\n",
      "48000000000000\n",
      "10000\n",
      "1\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "#Write  Python code lines to get the sum all numbers in a list\n",
    "# then get the result of multiplying them,\n",
    "# then get the largest number of them,\n",
    "# then get the smallest number of them,\n",
    "# finally get the numbers of items in that list.\n",
    "from math import prod\n",
    "my_list =[1,4,20,50,100,2000,10000,6]\n",
    "print(sum(my_list))\n",
    "print(prod(my_list))\n",
    "print(max(my_list))\n",
    "print(min(my_list))\n",
    "print(len(my_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PythonProgramming\n",
      "('P', 'y', 't', 'h', 'o', 'n', 'P', 'r', 'o', 'g', 'r', 'a', 'm', 'm', 'i', 'n', 'g')\n",
      "['P', 'y', 't', 'h', 'o', 'n', 'P', 'r', 'o', 'g', 'r', 'a', 'm', 'm', 'i', 'n', 'g']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#convert the following tuple into useful string:\n",
    "my_tuple = ('P','y','t','h','o','n','P','r','o','g','r','a','m','m','i','n','g')\n",
    "str1=''.join(my_tuple)\n",
    "print(str1)\n",
    "#convert string to a tuple\n",
    "str2=tuple(str1)\n",
    "print(str2)\n",
    "#convert tuple to a list\n",
    "str3=list(str2)\n",
    "print(str3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'orange', 'red', 'black', 'green', 'yellow'}\n"
     ]
    }
   ],
   "source": [
    "#union of sets\n",
    "\n",
    "a = {'red', 'yellow','orange','green'}\n",
    "b = {'red','orange','black'}\n",
    "\n",
    "union=a.union(b)\n",
    "print(union)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'orange', 'red', 'black', 'green', 'yellow'}\n",
      "{'orange', 'red', 10, 11, 12, 'green', 'yellow'}\n"
     ]
    }
   ],
   "source": [
    "#more union \n",
    "a = {'red', 'yellow','orange','green'}\n",
    "b = {'red','orange','black'}\n",
    "\n",
    "union=a.union(b)\n",
    "print(union)\n",
    "set3 = {10,11,12}\n",
    "union=a.union(set3)\n",
    "print(union)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1, 2, 3, 4, 5, 6, 7, 8, 9}\n",
      "{1, 2, 3, 4, 5, 6, 10, 11, 12}\n",
      "{1, 2, 3, 4, 5, 6, 10, 11, 12, 13}\n",
      "{3, 4, 5, 6}\n"
     ]
    }
   ],
   "source": [
    "#union and intersection\n",
    "set1 = {1,2,3,4,5,6}\n",
    "set2 = {4,5,6,7,8,9}\n",
    "set3 = {10,11,12}\n",
    "\n",
    "union=set1.union(set2)\n",
    "print(union)\n",
    "union=set1.union(set3)\n",
    "print(union)\n",
    "union.add(13)\n",
    "print(union)\n",
    "\n",
    "set4 = {3,4,5,6,7,8}\n",
    "intersection=union.intersection(set4)\n",
    "print(intersection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter your age:\n",
      "22\n",
      "your tiket will cost $10\n"
     ]
    }
   ],
   "source": [
    "'''Write a program in python check the person age \n",
    "then show him the price of train ticket that fit his age in dollars:Â¶\n",
    "children until 18 years ticket = 2\n",
    "old people bigger than or equal 60 years ticket = 5\n",
    "young people from 18 - 59 year ticket = 10\n",
    "and don't forget to declare your age:'''\n",
    "\n",
    "print('Enter your age:')\n",
    "age=int(input())\n",
    "if(age<1):\n",
    "    print('Invalid Age')\n",
    "elif(age<=18):\n",
    "    print('your tiket will cost $2')\n",
    "elif(age>18 & age<=59):\n",
    "    print('your tiket will cost $10')\n",
    "else:\n",
    "    print('your tiket will cost $5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48000000000000\n"
     ]
    }
   ],
   "source": [
    "#Using for loop write a python code that gives the multiply of the following list:\n",
    "my_list =[1,4,20,50,100,2000,10000,6]\n",
    "\n",
    "def multiply_this_list(this_list):\n",
    "    multiply_result = 1\n",
    "    for num in this_list:\n",
    "        multiply_result*= num\n",
    "    return multiply_result\n",
    "print(multiply_this_list(my_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence:  This cat belongs to madam Rachael\n",
      "Word Tokenize:  ['This', 'cat', 'belongs', 'to', 'madam', 'Rachael']\n",
      "Parts of Speech:  [('T', 'NNP'), ('h', 'NN'), ('i', 'NN'), ('s', 'VBP'), (' ', 'NNP'), ('c', 'VBP'), ('a', 'DT'), ('t', 'NN'), (' ', 'NN'), ('b', 'NN'), ('e', 'NN'), ('l', 'NN'), ('o', 'NN'), ('n', 'JJ'), ('g', 'NN'), ('s', 'NN'), (' ', 'NNP'), ('t', 'NN'), ('o', 'NN'), (' ', 'NNP'), ('m', 'VBZ'), ('a', 'DT'), ('d', 'NN'), ('a', 'DT'), ('m', 'NN'), (' ', 'NNP'), ('R', 'NNP'), ('a', 'DT'), ('c', 'NN'), ('h', 'NN'), ('a', 'DT'), ('e', 'NN'), ('l', 'NN')]\n"
     ]
    }
   ],
   "source": [
    "from nltk import pos_tag,word_tokenize\n",
    "sentence = \"This cat belongs to madam Rachael\"\n",
    "\n",
    "wordToken = word_tokenize(sentence)\n",
    "speech = pos_tag(sentence)\n",
    "print('Sentence: ',sentence)\n",
    "print('Word Tokenize: ',wordToken)\n",
    "print('Parts of Speech: ',speech)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop Worlds:  {'yourself', 'below', 'needn', 'have', 'against', 'between', 'same', 'll', 'most', 'or', 'yourselves', 's', 'as', 'by', 'whom', 'this', 'was', 'that', 'do', 'not', \"shan't\", 'wouldn', 've', 'i', \"you'll\", 'before', 'my', 'at', 'd', 'won', 'has', 'over', \"hasn't\", 'she', \"needn't\", 'myself', 'shan', 'only', 'than', 'should', \"doesn't\", 'ma', \"weren't\", \"you'd\", 'of', 'up', 'm', \"haven't\", 'doing', 'y', 'during', \"aren't\", \"wouldn't\", 'your', 'can', 'above', 'him', 'into', 'mustn', \"mightn't\", 'theirs', 'the', 'why', 'his', 'they', 'both', 'how', \"it's\", 'once', 'further', 'while', 'it', 'each', 'too', 'itself', 'own', 'out', \"wasn't\", 'had', 'some', 'such', \"couldn't\", 'those', 'mightn', 'does', 'her', 'if', 'ours', 'yours', 'there', \"hadn't\", 'haven', 'from', 'these', 'where', 'wasn', \"should've\", 'just', 'ourselves', 'no', 'being', 'about', 'for', 'nor', 'what', 'be', 'to', 'any', 'o', 'will', \"shouldn't\", 'here', 'ain', 'an', 'until', \"didn't\", 'down', 'herself', 'when', 'don', 'other', 'few', \"you're\", 'am', 'were', 'on', \"mustn't\", 'after', 'are', 'aren', 'their', 'its', 'but', 'because', 'so', \"don't\", 'under', 'hadn', 'who', 'more', 'doesn', 'hasn', \"that'll\", 'off', 'having', 'did', 'hers', 'through', 'a', \"you've\", 'couldn', 'you', 'we', 'themselves', 'then', 'and', 'he', 'which', \"isn't\", 'is', 'all', 'our', 're', 'himself', 'in', 'didn', 'been', \"she's\", 'again', \"won't\", 'them', 'shouldn', 'me', 'very', 'weren', 'isn', 't', 'with', 'now'}\n",
      "Sentence:  This cat belongs to madam Rachael\n",
      "Word Tokenize:  ['This', 'cat', 'belongs', 'to', 'madam', 'Rachael']\n",
      "Parts of Speech:  [('T', 'NNP'), ('h', 'NN'), ('i', 'NN'), ('s', 'VBP'), (' ', 'NNP'), ('c', 'VBP'), ('a', 'DT'), ('t', 'NN'), (' ', 'NN'), ('b', 'NN'), ('e', 'NN'), ('l', 'NN'), ('o', 'NN'), ('n', 'JJ'), ('g', 'NN'), ('s', 'NN'), (' ', 'NNP'), ('t', 'NN'), ('o', 'NN'), (' ', 'NNP'), ('m', 'VBZ'), ('a', 'DT'), ('d', 'NN'), ('a', 'DT'), ('m', 'NN'), (' ', 'NNP'), ('R', 'NNP'), ('a', 'DT'), ('c', 'NN'), ('h', 'NN'), ('a', 'DT'), ('e', 'NN'), ('l', 'NN')]\n",
      "Tokenized Sentence:  ['God is Great!', 'I won a lottery.']\n"
     ]
    }
   ],
   "source": [
    "from nltk import pos_tag,word_tokenize,sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "sentence = \"This cat belongs to madam Rachael\"\n",
    "text = \"God is Great! I won a lottery.\"\n",
    "wordToken = word_tokenize(sentence)\n",
    "tokenizedSentence = sent_tokenize(text)\n",
    "speech = pos_tag(sentence)\n",
    "stop_words=set(stopwords.words(\"english\"))\n",
    "print('Stop Worlds: ',stop_words)\n",
    "\n",
    "print('Sentence: ',sentence)\n",
    "print('Word Tokenize: ',wordToken)\n",
    "print('Parts of Speech: ',speech)\n",
    "print('Tokenized Sentence: ',tokenizedSentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import nltk\n",
    "import nltk.corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['abc', 'abc.zip', 'alpino', 'alpino.zip', 'biocreative_ppi', 'biocreative_ppi.zip', 'brown', 'brown.zip', 'brown_tei', 'brown_tei.zip', 'cess_cat', 'cess_cat.zip', 'cess_esp', 'cess_esp.zip', 'chat80', 'chat80.zip', 'city_database', 'city_database.zip', 'cmudict', 'cmudict.zip', 'comparative_sentences', 'comparative_sentences.zip', 'comtrans.zip', 'conll2000', 'conll2000.zip', 'conll2002', 'conll2002.zip', 'conll2007.zip', 'crubadan', 'crubadan.zip', 'dependency_treebank', 'dependency_treebank.zip', 'europarl_raw', 'europarl_raw.zip', 'floresta', 'floresta.zip', 'framenet_v15', 'framenet_v15.zip', 'framenet_v17', 'framenet_v17.zip', 'gazetteers', 'gazetteers.zip', 'genesis', 'genesis.zip', 'gutenberg', 'gutenberg.zip', 'ieer', 'ieer.zip', 'inaugural', 'inaugural.zip', 'indian', 'indian.zip', 'jeita.zip', 'kimmo', 'kimmo.zip', 'knbc.zip', 'lin_thesaurus', 'lin_thesaurus.zip', 'machado.zip', 'mac_morpho', 'mac_morpho.zip', 'masc_tagged.zip', 'movie_reviews', 'movie_reviews.zip', 'mte_teip5', 'mte_teip5.zip', 'names', 'names.zip', 'nombank.1.0.zip', 'nonbreaking_prefixes', 'nonbreaking_prefixes.zip', 'nps_chat', 'nps_chat.zip', 'omw', 'omw.zip', 'opinion_lexicon', 'opinion_lexicon.zip', 'panlex_swadesh.zip', 'paradigms', 'paradigms.zip', 'pil', 'pil.zip', 'pl196x', 'pl196x.zip', 'ppattach', 'ppattach.zip', 'problem_reports', 'problem_reports.zip', 'product_reviews_1', 'product_reviews_1.zip', 'product_reviews_2', 'product_reviews_2.zip', 'propbank.zip', 'pros_cons', 'pros_cons.zip', 'ptb', 'ptb.zip', 'qc', 'qc.zip', 'reuters.zip', 'rte', 'rte.zip', 'semcor.zip', 'senseval', 'senseval.zip', 'sentence_polarity', 'sentence_polarity.zip', 'sentiwordnet', 'sentiwordnet.zip', 'shakespeare', 'shakespeare.zip', 'sinica_treebank', 'sinica_treebank.zip', 'smultron', 'smultron.zip', 'state_union', 'state_union.zip', 'stopwords', 'stopwords.zip', 'subjectivity', 'subjectivity.zip', 'swadesh', 'swadesh.zip', 'switchboard', 'switchboard.zip', 'timit', 'timit.zip', 'toolbox', 'toolbox.zip', 'treebank', 'treebank.zip', 'twitter_samples', 'twitter_samples.zip', 'udhr', 'udhr.zip', 'udhr2', 'udhr2.zip', 'unicode_samples', 'unicode_samples.zip', 'universal_treebanks_v20.zip', 'verbnet', 'verbnet.zip', 'verbnet3', 'verbnet3.zip', 'webtext', 'webtext.zip', 'wordnet', 'wordnet.zip', 'wordnet_ic', 'wordnet_ic.zip', 'words', 'words.zip', 'ycoe', 'ycoe.zip']\n"
     ]
    }
   ],
   "source": [
    "print(os.listdir(nltk.data.find('corpora')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The', 'Fulton', 'County', 'Grand', 'Jury', 'said', ...]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import brown\n",
    "brown.words()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['austen-emma.txt',\n",
       " 'austen-persuasion.txt',\n",
       " 'austen-sense.txt',\n",
       " 'bible-kjv.txt',\n",
       " 'blake-poems.txt',\n",
       " 'bryant-stories.txt',\n",
       " 'burgess-busterbrown.txt',\n",
       " 'carroll-alice.txt',\n",
       " 'chesterton-ball.txt',\n",
       " 'chesterton-brown.txt',\n",
       " 'chesterton-thursday.txt',\n",
       " 'edgeworth-parents.txt',\n",
       " 'melville-moby_dick.txt',\n",
       " 'milton-paradise.txt',\n",
       " 'shakespeare-caesar.txt',\n",
       " 'shakespeare-hamlet.txt',\n",
       " 'shakespeare-macbeth.txt',\n",
       " 'whitman-leaves.txt']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.corpus.gutenberg.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[', 'Emma', 'by', 'Jane', 'Austen', '1816', ']', ...]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.corpus.gutenberg.words('austen-emma.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "192427"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nltk.corpus.gutenberg.words('austen-emma.txt'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "European authorities fined Google a record $5.1 billion on Wednesday for abusing its power in the mobile phone market and ordered the company to alter its practices\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tag import pos_tag\n",
    "\n",
    "ex = 'European authorities fined Google a record $5.1 billion on Wednesday for abusing its power in the mobile phone market and ordered the company to alter its practices'\n",
    "def preprocess(sent):\n",
    "    sent = nltk.word_tokenize(sent)\n",
    "    sent = nltk.pos_tag(sent)\n",
    "    return sent\n",
    "\n",
    "sent = preprocess(ex)\n",
    "print(ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Apple', 'has', 'laptop', 'of', 'model', 'MacBook', '.', 'Lenovo', 'has', 'laptop', 'of', 'model', 'Thinkpad', '.', 'Dell', 'has', 'laptop', 'of', 'inspiron', '.']\n",
      "[('Apple', 'NNP'), ('has', 'VBZ'), ('laptop', 'VBN'), ('of', 'IN'), ('model', 'NN'), ('MacBook', 'NNP'), ('.', '.'), ('Lenovo', 'NNP'), ('has', 'VBZ'), ('laptop', 'VBN'), ('of', 'IN'), ('model', 'NN'), ('Thinkpad', 'NNP'), ('.', '.'), ('Dell', 'NNP'), ('has', 'VBZ'), ('laptop', 'VBN'), ('of', 'IN'), ('inspiron', 'NN'), ('.', '.')]\n",
      "(NE Apple/NNP)\n",
      "('has', 'VBZ')\n",
      "('laptop', 'VBN')\n",
      "('of', 'IN')\n",
      "('model', 'NN')\n",
      "(NE MacBook/NNP)\n",
      "('.', '.')\n",
      "(NE Lenovo/NNP)\n",
      "('has', 'VBZ')\n",
      "('laptop', 'VBN')\n",
      "('of', 'IN')\n",
      "('model', 'NN')\n",
      "('Thinkpad', 'NNP')\n",
      "('.', '.')\n",
      "(NE Dell/NNP)\n",
      "('has', 'VBZ')\n",
      "('laptop', 'VBN')\n",
      "('of', 'IN')\n",
      "('inspiron', 'NN')\n",
      "('.', '.')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Entities</th>\n",
       "      <th>Labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MacBook</td>\n",
       "      <td>NE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lenovo</td>\n",
       "      <td>NE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dell</td>\n",
       "      <td>NE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Apple</td>\n",
       "      <td>NE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Entities Labels\n",
       "0  MacBook     NE\n",
       "1   Lenovo     NE\n",
       "2     Dell     NE\n",
       "3    Apple     NE"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "\n",
    "text = \"Apple has laptop of model MacBook. \\\n",
    "Lenovo has laptop of model Thinkpad.  \\\n",
    "Dell has laptop of inspiron.\"\n",
    "\n",
    "words = nltk.word_tokenize(text)\n",
    "print(words)\n",
    "\n",
    "pos_tags = nltk.pos_tag(words)\n",
    "print(pos_tags)\n",
    "\n",
    "chunks = nltk.ne_chunk(pos_tags, binary=True) #either NE or not NE\n",
    "for chunk in chunks:\n",
    "    print(chunk)\n",
    "\n",
    "entities = []\n",
    "labels = []\n",
    "for chunk in chunks:\n",
    "    if hasattr(chunk, 'label'):\n",
    "        # print(chunk)\n",
    "        entities.append(' '.join(c[0] for c in chunk))\n",
    "        labels.append(chunk.label())\n",
    "\n",
    "entities_labels = list(set(zip(entities, labels)))\n",
    "entities_df = pd.DataFrame(entities_labels)\n",
    "entities_df.columns = [\"Entities\", \"Labels\"]\n",
    "entities_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Apple', 'has', 'laptop', 'of', 'model', 'MacBook', '.', 'Lenovo', 'has', 'laptop', 'of', 'model', 'Thinkpad', '.', 'Dell', 'has', 'laptop', 'of', 'inspiron', '.']\n",
      "[('Apple', 'NNP'), ('has', 'VBZ'), ('laptop', 'VBN'), ('of', 'IN'), ('model', 'NN'), ('MacBook', 'NNP'), ('.', '.'), ('Lenovo', 'NNP'), ('has', 'VBZ'), ('laptop', 'VBN'), ('of', 'IN'), ('model', 'NN'), ('Thinkpad', 'NNP'), ('.', '.'), ('Dell', 'NNP'), ('has', 'VBZ'), ('laptop', 'VBN'), ('of', 'IN'), ('inspiron', 'NN'), ('.', '.')]\n",
      "(NE Apple/NNP)\n",
      "('has', 'VBZ')\n",
      "('laptop', 'VBN')\n",
      "('of', 'IN')\n",
      "('model', 'NN')\n",
      "(NE MacBook/NNP)\n",
      "('.', '.')\n",
      "(NE Lenovo/NNP)\n",
      "('has', 'VBZ')\n",
      "('laptop', 'VBN')\n",
      "('of', 'IN')\n",
      "('model', 'NN')\n",
      "('Thinkpad', 'NNP')\n",
      "('.', '.')\n",
      "(NE Dell/NNP)\n",
      "('has', 'VBZ')\n",
      "('laptop', 'VBN')\n",
      "('of', 'IN')\n",
      "('inspiron', 'NN')\n",
      "('.', '.')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Entities</th>\n",
       "      <th>Labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Apple</td>\n",
       "      <td>GPE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MacBook</td>\n",
       "      <td>ORGANIZATION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lenovo</td>\n",
       "      <td>GPE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dell</td>\n",
       "      <td>GPE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Entities        Labels\n",
       "0    Apple           GPE\n",
       "1  MacBook  ORGANIZATION\n",
       "2   Lenovo           GPE\n",
       "3     Dell           GPE"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "\n",
    "text = \"Apple has laptop of model MacBook. \\\n",
    "Lenovo has laptop of model Thinkpad.  \\\n",
    "Dell has laptop of inspiron.\"\n",
    "\n",
    "words = nltk.word_tokenize(text)\n",
    "print(words)\n",
    "\n",
    "pos_tags = nltk.pos_tag(words)\n",
    "print(pos_tags)\n",
    "\n",
    "chunks = nltk.ne_chunk(pos_tags, binary=True) #either NE or not NE\n",
    "for chunk in chunks:\n",
    "    print(chunk)\n",
    "\n",
    "entities = []\n",
    "labels = []\n",
    "\n",
    "sentence = nltk.sent_tokenize(text)\n",
    "for sent in sentence:\n",
    "    for chunk in nltk.ne_chunk(nltk.pos_tag(nltk.word_tokenize(sent)), binary=False):\n",
    "        if hasattr(chunk, 'label'):\n",
    "            entities.append(' '.join(c[0] for c in chunk))\n",
    "            labels.append(chunk.label())\n",
    "\n",
    "entities_labels = list(set(zip(entities, labels)))\n",
    "\n",
    "entities_df = pd.DataFrame(entities_labels)\n",
    "entities_df.columns = [\"Entities\", \"Labels\"]\n",
    "entities_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Apple', 'NNP'), ('has', 'VBZ'), ('laptop', 'VBN'), ('of', 'IN'), ('model', 'NN'), ('MacBook', 'NNP'), ('.', '.'), ('Lenovo', 'NNP'), ('has', 'VBZ'), ('laptop', 'VBN'), ('of', 'IN'), ('model', 'NN'), ('Thinkpad', 'NNP'), ('.', '.'), ('Dell', 'NNP'), ('has', 'VBZ'), ('laptop', 'VBN'), ('of', 'IN'), ('inspiron', 'NN'), ('.', '.')]\n",
      "(S\n",
      "  Apple/NNP\n",
      "  has/VBZ\n",
      "  laptop/VBN\n",
      "  of/IN\n",
      "  (NP model/NN)\n",
      "  MacBook/NNP\n",
      "  ./.\n",
      "  Lenovo/NNP\n",
      "  has/VBZ\n",
      "  laptop/VBN\n",
      "  of/IN\n",
      "  (NP model/NN)\n",
      "  Thinkpad/NNP\n",
      "  ./.\n",
      "  Dell/NNP\n",
      "  has/VBZ\n",
      "  laptop/VBN\n",
      "  of/IN\n",
      "  (NP inspiron/NN)\n",
      "  ./.)\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tag import pos_tag\n",
    "\n",
    "ex = \"Apple has laptop of model MacBook. \\\n",
    "Lenovo has laptop of model Thinkpad.  \\\n",
    "Dell has laptop of inspiron.\"\n",
    "\n",
    "def preprocess(sent):\n",
    "    sent = nltk.word_tokenize(sent)\n",
    "    sent = nltk.pos_tag(sent)\n",
    "    return sent\n",
    "\n",
    "sent = preprocess(ex)\n",
    "print(sent)\n",
    "\n",
    "pattern = 'NP: {<DT>?<JJ>*<NN>}'\n",
    "\n",
    "cp = nltk.RegexpParser(pattern)\n",
    "cs = cp.parse(sent)\n",
    "print(cs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: SpaCy in c:\\users\\dell\\anaconda3\\lib\\site-packages (2.3.5)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from SpaCy) (0.7.4)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from SpaCy) (0.8.0)\n",
      "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from SpaCy) (1.0.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from SpaCy) (4.50.2)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from SpaCy) (1.0.5)\n",
      "Requirement already satisfied: setuptools in c:\\users\\dell\\anaconda3\\lib\\site-packages (from SpaCy) (50.3.1.post20201107)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from SpaCy) (1.19.2)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from SpaCy) (2.0.5)\n",
      "Requirement already satisfied: thinc<7.5.0,>=7.4.1 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from SpaCy) (7.4.5)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from SpaCy) (3.0.5)\n",
      "Requirement already satisfied: plac<1.2.0,>=0.9.6 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from SpaCy) (0.9.6)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from SpaCy) (2.24.0)\n",
      "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from SpaCy) (1.0.5)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->SpaCy) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->SpaCy) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->SpaCy) (1.25.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->SpaCy) (2020.6.20)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install SpaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'en_core_web_sm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-e3796228f4af>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnlp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0men_core_web_sm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'en_core_web_sm' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "nlp = en_core_web_sm.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-23-cb2cf0ca7237>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-23-cb2cf0ca7237>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    pip3 install https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.0/en_core_web_sm-2.2.0.tar.gz\u001b[0m\n\u001b[1;37m         ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "pip3 install https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.0/en_core_web_sm-2.2.0.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-24-ea5104b4de49>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-24-ea5104b4de49>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    python3 -m spacy download en_core_web_sm\u001b[0m\n\u001b[1;37m               ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "python3 -m spacy download en_core_web_sm\n",
    "pip3 install https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.0/en_core_web_sm-2.2.0.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-25-15f5d4d939f2>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-25-15f5d4d939f2>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    python -m spacy download en_core_web_lg\u001b[0m\n\u001b[1;37m              ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "python -m spacy download en_core_web_lg\n",
    "python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Python was not found; run without arguments to install from the Microsoft Store, or disable this shortcut from Settings > Manage App Execution Aliases.\n"
     ]
    }
   ],
   "source": [
    "!python3 -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
